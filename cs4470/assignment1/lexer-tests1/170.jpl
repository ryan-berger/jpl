
fn relu(input : float) : float {
    return if input < 0.0 then 0.0 else input
}

fn dense(input[W, H] : float[,], weights[Wi, Hi, Wo, Ho] : float[,,,]) : float[,] {
    assert W == Wi && H == Hi, "Weight matrix doesn't match input size"
    return array[i : W, j : H] \
      relu(sum[i2 : W, j2 : H] input[i2, j2] * weights[i2, j2, i, j])
}

fn softmax(input[W, H] : float[,], weights[N, Wi, Hi] : float[,,]) : float[] {
    assert W == Wi && H == Hi, "Weight matrix doesn't match input size"
    let intermediate = array[n : N] sum[i : W, j : H] input[i, j] * weights[n, i, j]
    let expsum = sum[n : N] exp(intermediate[n])
    return array[n : N] exp(intermediate[n]) / expsum
}

fn bw(image[W, H] : float4[,], mi : float, ma : float) : float[,] {
    return array[i : W, j : H] image[i, j]{1} * (ma - mi) + mi // Green is a good lazy monochrome
}

fn max(a[N] : float[], i : int) : {int, float} {
    let { idx, val } = if N == i + 1 then {0, 0.0} else max(a, i + 1)
    return if val < a[i] then { i, a[i] } else { idx, val }
}

fn reshape(weights[DW, DH] : float[,], N : int, W : int, H : int) : {float[,,,], float[,,,], float[,,]} {
    assert DW == W*H + W*H + N, "Invalid data width"
    assert DH == W * H, "Invalid data height"
    return { \
        array[i : W, j : H, i2 : W, j2 : H] weights[i2 + j2 * W, i + j * W], \
        array[i : W, j : H, i2 : W, j2 : H] weights[W * H + i2 + j2 * W, i + j * W], \
        array[n : N, i2 : W, j2 : H] weights[2 * W * H + n, i2 + j2 * W] \
    }
}

fn recognize(image[W, H] : float[,], layer1 : float[,,,], layer2 : float[,,,], layer3 : float[,,]) : {int, float} {
    let i1 = dense(image, layer1)
    let i2 = dense(i1, layer2)
    let out = softmax(i2, layer3)
    return max(out, 0)
}

let { W, H, N } = { 28, 28, 10 }

read image "input.png" to input[IW, IH]
assert IW == W, "Invalid input width"
assert IH == H, "Invalid input height"

read image "layers.png" to layers[DW, DH]
assert DW == W*H + W*H + N, "Invalid layer data width"
assert DH == W * H, "Invalid layer data height"
let {layer1, layer2, layer3} = reshape(bw(layers, -0.22206303, 0.23117281), N, W, H)

time show recognize(bw(input, 0.0, 1.0), layer1, layer2, layer3)
